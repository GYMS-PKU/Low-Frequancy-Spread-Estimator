{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c18da0c0",
   "metadata": {},
   "source": [
    "## 四个主流估计器A股深交所的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cafb1f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import sys\n",
    "sys.path.append('C:/Users/Administrator/Desktop/Repositories/Low-Frequency-Spread-Estimator')\n",
    "sys.path.append('C:/Users/Handsome Bad Guy/Desktop/Repositories/Low-Frequency-Spread-Estimator')\n",
    "\n",
    "from SpreadEstimator.SpreadEstimator import SpreadEstimator\n",
    "from mytools.AutoTester import AutoTester\n",
    "\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f38f0cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "se = SpreadEstimator()\n",
    "univ = ~np.isnan(se.data.data_dic['close'])  # 合法的univ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3eac711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy(x,y,univ):\n",
    "    xx = []\n",
    "    yy = []\n",
    "    for i in range(len(x)):\n",
    "        se = (~np.isnan(x[i])) & univ[i] & (~np.isnan(y[i]))\n",
    "        if np.sum(se) == 0:\n",
    "            continue\n",
    "        xx.append(x[i:i+1, se].T)\n",
    "        yy.append(y[i,se])\n",
    "    return np.vstack(xx), np.hstack(yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5ac383",
   "metadata": {},
   "source": [
    "#### HL, 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28282ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41421356237309515\n",
      "0.1715728752538097\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(2)-1)\n",
    "print(3-np.sqrt(2)*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0f0df48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['spread', 'relative_spread', 'vol_wtd_rel_bas', 'vol_wtd_bas'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se.data.spread_dic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3ada28b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs_rel_sp\n",
      "mean corr: -0.1741, positive_corr_ratio: 0.0000, corr_IR: -2.8080\n",
      "0.0005274021274575184\n",
      "\n",
      "ts_rel_sp\n",
      "mean corr: -0.1647, positive_corr_ratio: 0.3353, corr_IR: -0.4054\n",
      "0.0005274021274575184\n",
      "\n",
      "cs_vol_rel_sp\n",
      "mean corr: -0.1588, positive_corr_ratio: 0.0000, corr_IR: -2.5224\n",
      "0.0005275614618757872\n",
      "\n",
      "ts_vol_rel_sp\n",
      "mean corr: -0.0852, positive_corr_ratio: 0.4165, corr_IR: -0.2100\n",
      "0.0005275614618757872\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "beta = 'prod{tsmean{powv{minus{logv{high},logv{low}},2},2},2}'\n",
    "\n",
    "high_1 = 'logv{tsdelay{high,1}}'\n",
    "low_1 = 'logv{tsdelay{low,1}}'\n",
    "con_1 = 'condition{gt{logv{low},logv{tsdelay{close,1}}},minus{logv{low},logv{tsdelay{close,1}}},minus{close,close}}'\n",
    "con_2 = 'condition{lt{logv{high},logv{tsdelay{close,1}}},minus{logv{high},logv{tsdelay{close,1}}},minus{close,close}}'\n",
    "con = 'add{' + con_1 + ',' + con_2 + '}'\n",
    "high_2 = 'minus{logv{high},' + con + '}'\n",
    "low_2 = 'minus{logv{low},' + con + '}'\n",
    "high = 'condition{ge{' + high_1 + ',' + high_2 + '},' + high_1 + ',' + high_2 + '}'\n",
    "low = 'condition{le{' + low_1 + ',' + low_2 + '},' + low_1 + ',' + low_2 + '}'\n",
    "\n",
    "gamma = 'powv{minus{' + high + ',' + low + '},2}'\n",
    "alpha = 'div{prod{' + 'powv{' + beta + ',0.5},0.4142},0.1716}'\n",
    "fml = 'minus{' + alpha + ',' + 'powv{' + 'div{' + gamma + ',0.1716},0.5}}'\n",
    "\n",
    "fml = 'div{' + 'minus{expv{' + fml + '},1},' + 'add{expv{' + fml + '},1}}'\n",
    "fml = 'condition{' + 'ge{' + fml +',0},' + fml + ',add{minus{close,close},0}}'\n",
    "fml = 'tsmean{' + fml + ',20}'\n",
    "\n",
    "\n",
    "\n",
    "print('cs_rel_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='cs', spread_type='relative_spread', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['relative_spread'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "print('ts_rel_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='ts', spread_type='relative_spread', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['relative_spread'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "print('cs_vol_rel_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='cs', spread_type='vol_wtd_rel_bas', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['vol_wtd_rel_bas'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "print('ts_vol_rel_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='ts', spread_type='vol_wtd_rel_bas', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['vol_wtd_rel_bas'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd7968c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_sp\n",
      "mean corr: 0.4855, positive_corr_ratio: 0.8990, corr_IR: 1.4419\n",
      "0.017850268346097955\n",
      "\n",
      "cs_sp\n",
      "mean corr: 0.7400, positive_corr_ratio: 1.0000, corr_IR: 20.5674\n",
      "0.017850268346097955\n",
      "\n",
      "cs_vol_sp\n",
      "mean corr: 0.7686, positive_corr_ratio: 1.0000, corr_IR: 21.7556\n",
      "0.017505156124712304\n",
      "\n",
      "ts_vol_sp\n",
      "mean corr: 0.5622, positive_corr_ratio: 0.9355, corr_IR: 1.8324\n",
      "0.017505156124712304\n"
     ]
    }
   ],
   "source": [
    "beta = 'prod{tsmean{powv{minus{high,low},2},2},2}'\n",
    "\n",
    "high_1 = 'tsdelay{high,1}'\n",
    "low_1 = 'tsdelay{low,1}'\n",
    "con_1 = 'condition{gt{low,tsdelay{close,1}},minus{low,tsdelay{close,1}},minus{close,close}}'\n",
    "con_2 = 'condition{lt{high,tsdelay{close,1}},minus{high,tsdelay{close,1}},minus{close,close}}'\n",
    "con = 'add{' + con_1 + ',' + con_2 + '}'\n",
    "high_2 = 'minus{high,' + con + '}'\n",
    "low_2 = 'minus{low,' + con + '}'\n",
    "high = 'condition{ge{' + high_1 + ',' + high_2 + '},' + high_1 + ',' + high_2 + '}'\n",
    "low = 'condition{le{' + low_1 + ',' + low_2 + '},' + low_1 + ',' + low_2 + '}'\n",
    "\n",
    "gamma = 'powv{minus{' + high + ',' + low + '},2}'\n",
    "alpha = 'div{prod{' + 'powv{' + beta + ',0.5},0.4142},0.1716}'\n",
    "fml = 'minus{' + alpha + ',' + 'powv{' + 'div{' + gamma + ',0.1716},0.5}}'\n",
    "\n",
    "fml = 'div{' + 'minus{expv{' + fml + '},1},' + 'add{expv{' + fml + '},1}}'\n",
    "fml = 'condition{' + 'ge{' + fml +',0},' + fml + ',add{minus{close,close},0}}'\n",
    "fml = 'tsmean{' + fml + ',20}'\n",
    "\n",
    "\n",
    "print('ts_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='ts', spread_type='spread', back=20)\n",
    "x, y = get_xy(signal, se.data.spread, univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "print('cs_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear', method='cs', spread_type='spread', back=20)\n",
    "x, y = get_xy(signal, se.data.spread, univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "print('cs_vol_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='cs', spread_type='vol_wtd_bas', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['vol_wtd_bas'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "print('ts_vol_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='ts', spread_type='vol_wtd_bas', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['vol_wtd_bas'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2a2077",
   "metadata": {},
   "source": [
    "#### Roll, 1999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adb44818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs_rel_sp\n",
      "mean corr: -0.2312, positive_corr_ratio: 0.0360, corr_IR: -3.0247\n",
      "0.0005314135600429788\n",
      "\n",
      "ts_rel_sp\n",
      "mean corr: -0.1263, positive_corr_ratio: 0.3559, corr_IR: -0.3411\n",
      "0.0005314135600429788\n",
      "\n",
      "cs_vol_rel_sp\n",
      "mean corr: -0.2129, positive_corr_ratio: 0.0495, corr_IR: -2.6078\n",
      "0.0005314253388228314\n",
      "\n",
      "ts_vol_rel_sp\n",
      "mean corr: -0.0443, positive_corr_ratio: 0.4406, corr_IR: -0.1193\n",
      "0.0005314253388228314\n"
     ]
    }
   ],
   "source": [
    "a = 'tsdelta{logv{close},1}'\n",
    "b = 'tsdelay{tsdelta{logv{close},1},1}'\n",
    "fml = 'prod{' + a + ',' + b +'}'\n",
    "fml = 'condition{' + 'ge{' + fml +',0},' + fml + ',add{minus{close,close},0}}'\n",
    "fml = 'tsmean{' + fml + ',20}'\n",
    "fml = 'powv{' + fml + ',0.5}'\n",
    "\n",
    "\n",
    "print('cs_rel_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='cs', spread_type='relative_spread', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['relative_spread'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "print('ts_rel_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='ts', spread_type='relative_spread', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['relative_spread'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "print('cs_vol_rel_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='cs', spread_type='vol_wtd_rel_bas', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['vol_wtd_rel_bas'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "print('ts_vol_rel_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='ts', spread_type='vol_wtd_rel_bas', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['vol_wtd_rel_bas'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d3e442a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs_sp\n",
      "mean corr: 0.7924, positive_corr_ratio: 1.0000, corr_IR: 18.7505\n",
      "0.016293619291864184\n",
      "\n",
      "ts_sp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2691: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2692: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean corr: 0.4327, positive_corr_ratio: 0.8657, corr_IR: 1.2250\n",
      "0.016293619291864184\n",
      "\n",
      "cs_vol_sp\n",
      "mean corr: 0.8213, positive_corr_ratio: 1.0000, corr_IR: 21.1992\n",
      "0.015708381698959887\n",
      "\n",
      "ts_vol_sp\n",
      "mean corr: 0.5197, positive_corr_ratio: 0.9225, corr_IR: 1.6242\n",
      "0.015708381698959887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2691: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2692: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "a = 'tsdelta{close,1}'\n",
    "b = 'tsdelay{tsdelta{close,1},1}'\n",
    "fml = 'prod{' + a + ',' + b +'}'\n",
    "fml = 'condition{' + 'ge{' + fml +',0},' + fml + ',add{minus{close,close},0}}'\n",
    "fml = 'tsmean{' + fml + ',20}'\n",
    "fml = 'powv{' + fml + ',0.5}'\n",
    "\n",
    "print('cs_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear', method='cs', spread_type='spread', back=20)\n",
    "x, y = get_xy(signal, se.data.spread, univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "print('ts_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='ts', spread_type='spread', back=20)\n",
    "x, y = get_xy(signal, se.data.spread, univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "print('cs_vol_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='cs', spread_type='vol_wtd_bas', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['vol_wtd_bas'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "print('ts_vol_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='ts', spread_type='vol_wtd_bas', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['vol_wtd_bas'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4fc49e",
   "metadata": {},
   "source": [
    "#### CHL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4239dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs_rel_sp\n",
      "mean corr: -0.2317, positive_corr_ratio: 0.0000, corr_IR: -3.9265\n",
      "0.0005261585578705452\n",
      "\n",
      "ts_rel_sp\n",
      "mean corr: -0.1452, positive_corr_ratio: 0.3410, corr_IR: -0.3764\n",
      "0.0005261585578705452\n",
      "\n",
      "cs_vol_rel_sp\n",
      "mean corr: -0.2157, positive_corr_ratio: 0.0000, corr_IR: -3.4754\n",
      "0.0005266709233627771\n",
      "\n",
      "ts_vol_rel_sp\n",
      "mean corr: -0.0652, positive_corr_ratio: 0.4276, corr_IR: -0.1682\n",
      "0.0005266709233627771\n"
     ]
    }
   ],
   "source": [
    "a = 'minus{logv{tsdelay{close,1}},div{add{logv{tsdelay{high,1}},logv{tsdelay{low,1}}},2}}'\n",
    "b = 'minus{logv{tsdelay{close,1}},div{add{logv{high},logv{low}},2}}'\n",
    "fml = 'prod{' + a + ',' + b +'}'\n",
    "fml = 'condition{' + 'ge{' + fml +',0},' + fml + ',add{minus{close,close},0}}'\n",
    "fml = 'tsmean{' + fml + ',20}'\n",
    "fml = 'powv{' + fml + ',0.5}'\n",
    "\n",
    "print('cs_rel_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='cs', spread_type='relative_spread', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['relative_spread'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "print('ts_rel_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='ts', spread_type='relative_spread', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['relative_spread'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "print('cs_vol_rel_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='cs', spread_type='vol_wtd_rel_bas', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['vol_wtd_rel_bas'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "print('ts_vol_rel_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='ts', spread_type='vol_wtd_rel_bas', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['vol_wtd_rel_bas'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb312e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs_sp\n",
      "mean corr: 0.8069, positive_corr_ratio: 1.0000, corr_IR: 18.1490\n",
      "0.01608914260675741\n",
      "\n",
      "ts_sp\n",
      "mean corr: 0.4472, positive_corr_ratio: 0.8773, corr_IR: 1.2842\n",
      "0.01608914260675741\n",
      "\n",
      "cs_vol_sp\n",
      "mean corr: 0.8335, positive_corr_ratio: 1.0000, corr_IR: 19.7509\n",
      "0.015576776278580222\n",
      "\n",
      "ts_vol_sp\n",
      "mean corr: 0.5317, positive_corr_ratio: 0.9250, corr_IR: 1.6688\n",
      "0.015576776278580222\n"
     ]
    }
   ],
   "source": [
    "a = 'minus{tsdelay{close,1},div{add{tsdelay{high,1},tsdelay{low,1}},2}}'\n",
    "b = 'minus{tsdelay{close,1},div{add{high,low},2}}'\n",
    "fml = 'prod{' + a + ',' + b +'}'\n",
    "fml = 'condition{' + 'ge{' + fml +',0},' + fml + ',add{minus{close,close},0}}'\n",
    "fml = 'tsmean{' + fml + ',20}'\n",
    "fml = 'powv{' + fml + ',0.5}'\n",
    "\n",
    "print('cs_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear', method='cs', spread_type='spread', back=20)\n",
    "x, y = get_xy(signal, se.data.spread, univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "print('ts_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='ts', spread_type='spread', back=20)\n",
    "x, y = get_xy(signal, se.data.spread, univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "print('cs_vol_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='cs', spread_type='vol_wtd_bas', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['vol_wtd_bas'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "print('ts_vol_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='ts', spread_type='vol_wtd_bas', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['vol_wtd_bas'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a55209",
   "metadata": {},
   "source": [
    "#### last_bas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46492274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs_rel_sp\n",
      "mean corr: 0.7343, positive_corr_ratio: 1.0000, corr_IR: 7.4584\n",
      "0.00031485678446564606\n",
      "\n",
      "ts_rel_sp\n",
      "mean corr: 0.3222, positive_corr_ratio: 0.9692, corr_IR: 1.3094\n",
      "0.00031485678446564606\n",
      "\n",
      "cs_vol_rel_sp\n",
      "mean corr: 0.7341, positive_corr_ratio: 1.0000, corr_IR: 7.3904\n",
      "0.00031638635710163444\n",
      "\n",
      "ts_vol_rel_sp\n",
      "mean corr: 0.3078, positive_corr_ratio: 0.9640, corr_IR: 1.2554\n",
      "0.00031638635710163444\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "fml = 'last_rel_bas'\n",
    "\n",
    "print('cs_rel_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='cs', spread_type='relative_spread', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['relative_spread'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "print('ts_rel_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='ts', spread_type='relative_spread', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['relative_spread'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "print('cs_vol_rel_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='cs', spread_type='vol_wtd_rel_bas', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['vol_wtd_rel_bas'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "print('ts_vol_rel_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='ts', spread_type='vol_wtd_rel_bas', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['vol_wtd_rel_bas'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc164dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs_sp\n",
      "mean corr: 0.5655, positive_corr_ratio: 1.0000, corr_IR: 6.0078\n",
      "0.01809021668964128\n",
      "\n",
      "ts_sp\n",
      "mean corr: 0.1231, positive_corr_ratio: 0.8308, corr_IR: 0.9220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2691: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2692: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01809021668964128\n",
      "\n",
      "cs_vol_sp\n",
      "mean corr: 0.5633, positive_corr_ratio: 1.0000, corr_IR: 6.1431\n",
      "0.01841368404684135\n",
      "\n",
      "ts_vol_sp\n",
      "mean corr: 0.1135, positive_corr_ratio: 0.8014, corr_IR: 0.8327\n",
      "0.01841368404684135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2691: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2692: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "fml = 'last_bas'\n",
    "\n",
    "print('cs_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear', method='cs', spread_type='spread', back=20)\n",
    "x, y = get_xy(signal, se.data.spread, univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "print('ts_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='ts', spread_type='spread', back=20)\n",
    "x, y = get_xy(signal, se.data.spread, univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "print('cs_vol_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='cs', spread_type='vol_wtd_bas', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['vol_wtd_bas'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "print('ts_vol_sp')\n",
    "stats, signal = se.test_factor(fml, corr_type='linear',method='ts', spread_type='vol_wtd_bas', back=20)\n",
    "x, y = get_xy(signal, se.data.spread_dic['vol_wtd_bas'], univ)\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ac432d",
   "metadata": {},
   "source": [
    "#### LOT_Mix\n",
    "\n",
    "我们使用torch来进行优化求解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df7823cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LOTNet(nn.Module):\n",
    "    def __init__(self, sample_num: int = 1):\n",
    "        \"\"\"\n",
    "        :param sample_num: 样本数量\n",
    "        \"\"\"\n",
    "        super(LOTNet, self).__init__()\n",
    "        self.sample_num = sample_num\n",
    "        self.sigma = nn.Parameter(0.01 * torch.ones(sample_num))  \n",
    "        self.beta = nn.Parameter(torch.ones(1, sample_num))\n",
    "        self.alpha_1 = nn.Parameter(0.01 * torch.ones(1, sample_num))\n",
    "        self.alpha_2 = nn.Parameter(-0.01 * torch.ones(1, sample_num))\n",
    "        \n",
    "    def forward(self, R, R_m):  # 传入的R是seq_length * sample_num，R_m是seq_length * 1\n",
    "        R_1 = R + self.alpha_1.repeat(len(R), 1) - torch.matmul(R_m, self.beta)\n",
    "        R_2 = R + self.alpha_2.repeat(len(R), 1) - torch.matmul(R_m, self.beta)\n",
    "        R_t = torch.where(R>0, R_1, R_2)\n",
    "        R_t = torch.sum(R_t**2, dim=0) / (2 * self.sigma ** 2)\n",
    "        # print(R_t.shape)\n",
    "        return -len(R)/2 * torch.log(1e-8+self.sigma**2) - R_t\n",
    "    \n",
    "class MyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyLoss, self).__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return -torch.mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "273cc834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean corr: 0.0090, positive_corr_ratio: 0.5893, corr_IR: 0.0926\n"
     ]
    }
   ],
   "source": [
    "# 获得R_m和每个股票的日收益率\n",
    "fml = 'tspct{close,1}'\n",
    "stats, ret = se.test_factor(fml, corr_type='linear',method='cs', spread_type='spread')\n",
    "ret = ret.astype(np.float32)\n",
    "ret[np.isnan(ret)] = 0\n",
    "R_m = np.zeros(len(ret), dtype=np.float32)\n",
    "R_m[1:] = np.nanmean(ret[1:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "666c4997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 done. time used: 0.2642s\n",
      "22 done. time used: 0.5277s\n",
      "23 done. time used: 0.7939s\n",
      "24 done. time used: 1.0582s\n",
      "25 done. time used: 1.3264s\n",
      "26 done. time used: 1.5917s\n",
      "27 done. time used: 1.8589s\n",
      "28 done. time used: 2.1231s\n",
      "29 done. time used: 2.3874s\n",
      "30 done. time used: 2.6501s\n",
      "31 done. time used: 2.9176s\n",
      "32 done. time used: 3.1831s\n",
      "33 done. time used: 3.4485s\n",
      "34 done. time used: 3.7133s\n",
      "35 done. time used: 3.9825s\n",
      "36 done. time used: 4.2477s\n",
      "37 done. time used: 4.5128s\n",
      "38 done. time used: 4.7770s\n",
      "39 done. time used: 5.0390s\n",
      "40 done. time used: 5.3040s\n",
      "41 done. time used: 5.5713s\n",
      "42 done. time used: 5.8387s\n",
      "43 done. time used: 6.1029s\n",
      "44 done. time used: 6.3671s\n",
      "45 done. time used: 6.6314s\n",
      "46 done. time used: 6.8986s\n",
      "47 done. time used: 7.1599s\n",
      "48 done. time used: 7.4211s\n",
      "49 done. time used: 7.6863s\n",
      "50 done. time used: 7.9558s\n",
      "51 done. time used: 8.2209s\n",
      "52 done. time used: 8.4845s\n",
      "53 done. time used: 8.7531s\n",
      "54 done. time used: 9.0208s\n",
      "55 done. time used: 9.2848s\n",
      "56 done. time used: 9.5506s\n",
      "57 done. time used: 9.8198s\n",
      "58 done. time used: 10.0877s\n",
      "59 done. time used: 10.3559s\n",
      "60 done. time used: 10.6287s\n",
      "61 done. time used: 10.8979s\n",
      "62 done. time used: 11.1663s\n",
      "63 done. time used: 11.4332s\n",
      "64 done. time used: 11.6985s\n",
      "65 done. time used: 11.9636s\n",
      "66 done. time used: 12.2258s\n",
      "67 done. time used: 12.4896s\n",
      "68 done. time used: 12.7588s\n",
      "69 done. time used: 13.0227s\n",
      "70 done. time used: 13.2889s\n",
      "71 done. time used: 13.5580s\n",
      "72 done. time used: 13.8273s\n",
      "73 done. time used: 14.0941s\n",
      "74 done. time used: 14.3583s\n",
      "75 done. time used: 14.6241s\n",
      "76 done. time used: 14.8943s\n",
      "77 done. time used: 15.1632s\n",
      "78 done. time used: 15.4279s\n",
      "79 done. time used: 15.6952s\n",
      "80 done. time used: 15.9644s\n",
      "81 done. time used: 16.2348s\n",
      "82 done. time used: 16.5002s\n",
      "83 done. time used: 16.7662s\n",
      "84 done. time used: 17.0271s\n",
      "85 done. time used: 17.2922s\n",
      "86 done. time used: 17.5580s\n",
      "87 done. time used: 17.8283s\n",
      "88 done. time used: 18.0964s\n",
      "89 done. time used: 18.3596s\n",
      "90 done. time used: 18.6234s\n",
      "91 done. time used: 18.8937s\n",
      "92 done. time used: 19.1575s\n",
      "93 done. time used: 19.4183s\n",
      "94 done. time used: 19.6825s\n",
      "95 done. time used: 19.9547s\n",
      "96 done. time used: 20.2208s\n",
      "97 done. time used: 20.4851s\n",
      "98 done. time used: 20.7533s\n",
      "99 done. time used: 21.0170s\n",
      "100 done. time used: 21.2850s\n",
      "101 done. time used: 21.5499s\n",
      "102 done. time used: 21.8152s\n",
      "103 done. time used: 22.0796s\n",
      "104 done. time used: 22.3498s\n",
      "105 done. time used: 22.6208s\n",
      "106 done. time used: 22.8940s\n",
      "107 done. time used: 23.1638s\n",
      "108 done. time used: 23.4334s\n",
      "109 done. time used: 23.7027s\n",
      "110 done. time used: 23.9689s\n",
      "111 done. time used: 24.2287s\n",
      "112 done. time used: 24.4935s\n",
      "113 done. time used: 24.7650s\n",
      "114 done. time used: 25.0304s\n",
      "115 done. time used: 25.2960s\n",
      "116 done. time used: 25.5613s\n",
      "117 done. time used: 25.8364s\n",
      "118 done. time used: 26.1023s\n",
      "119 done. time used: 26.3662s\n",
      "120 done. time used: 26.6294s\n",
      "121 done. time used: 26.9112s\n",
      "122 done. time used: 27.1801s\n",
      "123 done. time used: 27.4506s\n",
      "124 done. time used: 27.7251s\n",
      "125 done. time used: 27.9960s\n",
      "126 done. time used: 28.2662s\n",
      "127 done. time used: 28.5320s\n",
      "128 done. time used: 28.8013s\n",
      "129 done. time used: 29.0798s\n",
      "130 done. time used: 29.3479s\n",
      "131 done. time used: 29.6145s\n",
      "132 done. time used: 29.8888s\n",
      "133 done. time used: 30.1593s\n",
      "134 done. time used: 30.4291s\n",
      "135 done. time used: 30.6992s\n",
      "136 done. time used: 30.9734s\n",
      "137 done. time used: 31.2484s\n",
      "138 done. time used: 31.5218s\n",
      "139 done. time used: 31.7946s\n",
      "140 done. time used: 32.0615s\n",
      "141 done. time used: 32.3327s\n",
      "142 done. time used: 32.6019s\n",
      "143 done. time used: 32.8742s\n",
      "144 done. time used: 33.1390s\n",
      "145 done. time used: 33.4050s\n",
      "146 done. time used: 33.6733s\n",
      "147 done. time used: 33.9535s\n",
      "148 done. time used: 34.2263s\n",
      "149 done. time used: 34.5039s\n",
      "150 done. time used: 34.7801s\n",
      "151 done. time used: 35.0500s\n",
      "152 done. time used: 35.3167s\n",
      "153 done. time used: 35.5832s\n",
      "154 done. time used: 35.8504s\n",
      "155 done. time used: 36.1134s\n",
      "156 done. time used: 36.3792s\n",
      "157 done. time used: 36.6500s\n",
      "158 done. time used: 36.9222s\n",
      "159 done. time used: 37.1890s\n",
      "160 done. time used: 37.4541s\n",
      "161 done. time used: 37.7241s\n",
      "162 done. time used: 37.9892s\n",
      "163 done. time used: 38.2580s\n",
      "164 done. time used: 38.5200s\n",
      "165 done. time used: 38.7909s\n",
      "166 done. time used: 39.0576s\n",
      "167 done. time used: 39.3269s\n",
      "168 done. time used: 39.5928s\n",
      "169 done. time used: 39.8640s\n",
      "170 done. time used: 40.1290s\n",
      "171 done. time used: 40.3969s\n",
      "172 done. time used: 40.6601s\n",
      "173 done. time used: 40.9253s\n",
      "174 done. time used: 41.1902s\n",
      "175 done. time used: 41.4558s\n",
      "176 done. time used: 41.7384s\n",
      "177 done. time used: 42.0113s\n",
      "178 done. time used: 42.2841s\n",
      "179 done. time used: 42.5582s\n",
      "180 done. time used: 42.8317s\n",
      "181 done. time used: 43.0955s\n",
      "182 done. time used: 43.3640s\n",
      "183 done. time used: 43.6348s\n",
      "184 done. time used: 43.9086s\n",
      "185 done. time used: 44.1772s\n",
      "186 done. time used: 44.4500s\n",
      "187 done. time used: 44.7188s\n",
      "188 done. time used: 44.9925s\n",
      "189 done. time used: 45.2587s\n",
      "190 done. time used: 45.5223s\n",
      "191 done. time used: 45.7887s\n",
      "192 done. time used: 46.0574s\n",
      "193 done. time used: 46.3232s\n",
      "194 done. time used: 46.5899s\n",
      "195 done. time used: 46.8603s\n",
      "196 done. time used: 47.1289s\n",
      "197 done. time used: 47.3964s\n",
      "198 done. time used: 47.6611s\n",
      "199 done. time used: 47.9254s\n",
      "200 done. time used: 48.1878s\n",
      "201 done. time used: 48.4538s\n",
      "202 done. time used: 48.7197s\n",
      "203 done. time used: 48.9883s\n",
      "204 done. time used: 49.2549s\n",
      "205 done. time used: 49.5212s\n",
      "206 done. time used: 49.7900s\n",
      "207 done. time used: 50.0587s\n",
      "208 done. time used: 50.3241s\n",
      "209 done. time used: 50.5908s\n",
      "210 done. time used: 50.8597s\n",
      "211 done. time used: 51.1269s\n",
      "212 done. time used: 51.3954s\n",
      "213 done. time used: 51.6627s\n",
      "214 done. time used: 51.9360s\n",
      "215 done. time used: 52.2088s\n",
      "216 done. time used: 52.4790s\n",
      "217 done. time used: 52.7497s\n",
      "218 done. time used: 53.0136s\n",
      "219 done. time used: 53.2829s\n",
      "220 done. time used: 53.5506s\n",
      "221 done. time used: 53.8208s\n",
      "222 done. time used: 54.0871s\n",
      "223 done. time used: 54.3547s\n",
      "224 done. time used: 54.6200s\n",
      "225 done. time used: 54.8902s\n",
      "226 done. time used: 55.1599s\n",
      "227 done. time used: 55.4250s\n",
      "228 done. time used: 55.7024s\n",
      "229 done. time used: 55.9809s\n",
      "230 done. time used: 56.2675s\n",
      "231 done. time used: 56.5401s\n",
      "232 done. time used: 56.8148s\n",
      "233 done. time used: 57.0876s\n",
      "234 done. time used: 57.3609s\n",
      "235 done. time used: 57.6321s\n",
      "236 done. time used: 57.9062s\n",
      "237 done. time used: 58.1743s\n",
      "238 done. time used: 58.4447s\n",
      "239 done. time used: 58.7149s\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "model = LOTNet(2081).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=0)\n",
    "loss_func = MyLoss()\n",
    "\n",
    "r_m = torch.Tensor(R_m).unsqueeze(-1).to(device)\n",
    "r = torch.Tensor(ret).to(device)\n",
    "\n",
    "# R_m = torch.Tensor(R_m[1:51]).unsqueeze(-1).to(device)\n",
    "# R = torch.Tensor(ret[1:51]).to(device)\n",
    "\n",
    "signal = np.zeros((240, 2081))\n",
    "t = time()\n",
    "for j in range(21, 240):\n",
    "    for i in range(200):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_func(model(r[j-20:j+1], r_m[j-20:j+1]))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if (i + 1) % 100 == 0:\n",
    "#             print('epoch {}'.format(i + 1))\n",
    "#             print('loss: {:.4f}, time used: {:.4f}s'.format(float(loss), time()-t))\n",
    "    model.eval()\n",
    "    signal[j] = (model.alpha_1 - model.alpha_2).detach().cpu().numpy()\n",
    "    print('{} done. time used: {:.4f}s'.format(j, time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "893f9aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs_sp\n",
      "mean corr: -0.0421, positive_corr_ratio: 0.0137, corr_IR: -1.8660\n",
      "0.02333245055586285\n",
      "\n",
      "cs_rel_sp\n",
      "mean corr: 0.0481, positive_corr_ratio: 0.9269, corr_IR: 1.0614\n",
      "0.0005328161731098392\n",
      "\n",
      "ts_sp\n",
      "mean corr: -0.1205, positive_corr_ratio: 0.2773, corr_IR: -0.6040\n",
      "0.022896406990260066\n",
      "\n",
      "ts_rel_sp\n",
      "mean corr: 0.0915, positive_corr_ratio: 0.6406, corr_IR: 0.3889\n",
      "0.0005328161731098392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('cs_sp')\n",
    "stats = AT.test(signal[21:], se.data.spread[21:240], corr_type='linear',method='cs')\n",
    "print('mean corr: {:.4f}, positive_corr_ratio: {:.4f}, corr_IR: {:.4f}'.\n",
    "              format(stats.mean_corr, stats.positive_corr_ratio, stats.corr_IR))\n",
    "x, y = get_xy(signal[51:], se.data.spread[21:240], univ[21:240])\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "print('cs_rel_sp')\n",
    "stats = AT.test(signal[21:], se.data.spread_dic['relative_spread'][21:240], corr_type='linear',method='cs')\n",
    "print('mean corr: {:.4f}, positive_corr_ratio: {:.4f}, corr_IR: {:.4f}'.\n",
    "              format(stats.mean_corr, stats.positive_corr_ratio, stats.corr_IR))\n",
    "x, y = get_xy(signal[21:], se.data.spread_dic['relative_spread'][21:240], univ[21:240])\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "print('ts_sp')\n",
    "stats = AT.test(signal[21:], se.data.spread[21:240], corr_type='linear',method='ts')\n",
    "print('mean corr: {:.4f}, positive_corr_ratio: {:.4f}, corr_IR: {:.4f}'.\n",
    "              format(stats.mean_corr, stats.positive_corr_ratio, stats.corr_IR))\n",
    "x, y = get_xy(signal[21:], se.data.spread[21:240], univ[21:240])\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "print('ts_rel_sp')\n",
    "stats = AT.test(signal[21:], se.data.spread_dic['relative_spread'][21:240], corr_type='linear',method='ts')\n",
    "print('mean corr: {:.4f}, positive_corr_ratio: {:.4f}, corr_IR: {:.4f}'.\n",
    "              format(stats.mean_corr, stats.positive_corr_ratio, stats.corr_IR))\n",
    "x, y = get_xy(signal[21:], se.data.spread_dic['relative_spread'][21:240], univ[21:240])\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581efa94",
   "metadata": {},
   "source": [
    "#### Gibbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90bc836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close合法的top\n",
    "top = np.sum(np.isnan(se.data.data_dic['close']),axis=0)<=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aaefc9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_gibbs = np.zeros((210,np.sum(top)))\n",
    "for i in range(10):\n",
    "    c = np.load('../estimator/cache/{}.npy'.format(i))\n",
    "    signal_gibbs[21*i:21*i+21] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aee82d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs_sp\n",
      "mean corr: 0.0024, positive_corr_ratio: 0.5286, corr_IR: 0.1088\n",
      "0.02302115877274065\n",
      "\n",
      "cs_rel_sp\n",
      "mean corr: -0.0006, positive_corr_ratio: 0.4429, corr_IR: -0.0281\n",
      "0.0005328121884986163\n",
      "\n",
      "ts_sp\n",
      "mean corr: -0.0004, positive_corr_ratio: 0.5017, corr_IR: -0.0057\n",
      "0.02302115877274065\n",
      "\n",
      "ts_rel_sp\n",
      "mean corr: 0.0004, positive_corr_ratio: 0.5070, corr_IR: 0.0060\n",
      "0.0005328121884986163\n"
     ]
    }
   ],
   "source": [
    "print('cs_sp')\n",
    "stats = AT.test(signal_gibbs, se.data.spread[20:230,top], corr_type='linear',method='cs')\n",
    "print('mean corr: {:.4f}, positive_corr_ratio: {:.4f}, corr_IR: {:.4f}'.\n",
    "              format(stats.mean_corr, stats.positive_corr_ratio, stats.corr_IR))\n",
    "x, y = get_xy(signal_gibbs, se.data.spread[20:230,top], univ[20:230,top])\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "print('cs_rel_sp')\n",
    "stats = AT.test(signal_gibbs, se.data.spread_dic['relative_spread'][20:230,top], corr_type='linear',method='cs')\n",
    "print('mean corr: {:.4f}, positive_corr_ratio: {:.4f}, corr_IR: {:.4f}'.\n",
    "              format(stats.mean_corr, stats.positive_corr_ratio, stats.corr_IR))\n",
    "x, y = get_xy(signal_gibbs, se.data.spread_dic['relative_spread'][20:230,top], univ[20:230,top])\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "print('ts_sp')\n",
    "stats = AT.test(signal_gibbs, se.data.spread[20:230,top], corr_type='linear',method='ts')\n",
    "print('mean corr: {:.4f}, positive_corr_ratio: {:.4f}, corr_IR: {:.4f}'.\n",
    "              format(stats.mean_corr, stats.positive_corr_ratio, stats.corr_IR))\n",
    "x, y = get_xy(signal_gibbs, se.data.spread[20:230,top], univ[20:230,top])\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))\n",
    "print()\n",
    "\n",
    "print('ts_rel_sp')\n",
    "stats = AT.test(signal_gibbs, se.data.spread_dic['relative_spread'][20:230,top], corr_type='linear',method='ts')\n",
    "print('mean corr: {:.4f}, positive_corr_ratio: {:.4f}, corr_IR: {:.4f}'.\n",
    "              format(stats.mean_corr, stats.positive_corr_ratio, stats.corr_IR))\n",
    "x, y = get_xy(signal_gibbs, se.data.spread_dic['relative_spread'][20:230,top], univ[20:230,top])\n",
    "lr.fit(x, y)\n",
    "print(np.sqrt(np.mean((y-lr.predict(x))**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b2096c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
